
# ====================
#GEMINI_MODEL, по умолчанию gemini-2.0-flash

GEMINI_MODEL=gemini-2.5-flash-lite

# ==================== ОСНОВНЫЕ РЕЖИМЫ ====================

# STREAMING_ENABLED управляет тем, разрешает ли бэкенд использование стримингового эндпоинта
# (выключено): /chat_stream возвращает ошибку 403, и расширение переключается на использование /chat (один JSON-ответ).
# 1 (включено): /chat_stream возвращает текстовый поток (text/plain) с инкрементными токенами. Для этого также требуется GEMINI_API_KEY; без этого ключа /chat_stream возвращает 403.
# Устанавливайте 0 во время отладки или при нестабильной сети, чтобы избежать зависаний и сохранить простоту поведения.
# Устанавливайте 1 для рабочей среды или когда вам нужны постепенные обновления по токенам и у вас есть действительный GEMINI_API_KEY (и, опционально, EXA_API_KEY).
# Стабильность (0) vs интерактивность (1)

# Стабильность (0) vs интерактивность (1)
STREAMING_ENABLED=1                    # Для Chrome-расширения - стабильность важнее


# ==================== ПАРАМЕТРЫ RAG ====================
# ВКЛЮЧАЕМ RAG - это основа работы!
RAG_ENABLED=1
# Увеличиваем для лучшего покрытия страницы
RAG_TOP_K=8
# RAG_DEBUG=1 - для отладки
RAG_DEBUG=1
# ==================== ПАРАМЕТРЫ ГРАФА ====================
# Размер чанка для веб-контента
LG_CHUNK_SIZE=600                      # Оптимально для фрагментарного веб-контента
LG_CHUNK_OVERLAP=90                    # 15% перекрытия для сохранения контекста

# Автоматически вычисляемые параметры (можно убрать из конфига)
# минимальная общая длина текста для включения разбиения. Если 0, используется 2×LG_CHUNK_SIZE
LG_CHUNK_MIN_TOTAL=0                # 2 × LG_CHUNK_SIZE (вычислять автоматически)

# Количество извлекаемых чанков
LG_CHUNK_NOTES_MAX_CHUNKS=8            # Синхронизируем с RAG_TOP_K
# LG_NOTES_MAX: максимум заметок, которые собираем на шаге chunk_notes (сколько пунктов вообще
# генерируем из текста). по умолчанию 12, чем больше заметок тем богаче ответ
LG_NOTES_MAX=8                        # Баланс между богатством и шумом
# LG_NOTES_SHOW_MAX: максимум заметок, которые включаем в промпт (сколько реально пойдёт в LLM)
LG_NOTES_SHOW_MAX = 10
# Бюджет контекста для промпта
LG_PROMPT_TEXT_CHARS=12000              # Используем возможности Gemini

# ==================== ИНТЕЛЛЕКТУАЛЬНЫЙ ПОИСК ====================

# Когда активировать поиск Exa
LG_SEARCH_MIN_CONTEXT_CHARS=400        # Более чувствительный порог

# Настройки Exa
#сколько сниппетов EXA включать в промпт (по умолчанию 3).увеличение снижает скорость
LG_EXA_TIME_BUDGET_S=4.0               # Для Chrome-расширения важна скорость
# включить мягкие эвристики поиска = 1, отключить = 0
LG_SEARCH_HEURISTICS=1                 # Оставляем умные решения
# LG_SEARCH_RESULTS_MAX - сколько сниппетов EXA включать в промпт
LG_SEARCH_RESULTS_MAX=3                # Баланс: больше ≠ лучше
# LG_SEARCH_SNIPPET_CHARS -длина каждого сниппета (по умолчанию 300). Диапазон 400–600.
LG_SEARCH_SNIPPET_CHARS=500            # Достаточно для информативных сниппетов
# LG_ANSWER_MAX_SENTENCES - это ограничитель длины итогового ответа в предложениях (постобработка).
# 0: отключено (не сокращаем).
# >0: обрезаем финальный ответ до указанного числа предложений.
LG_ANSWER_MAX_SENTENCES=0
# ==================== ДЕБАГ (ОПЦИОНАЛЬНО) ====================

LANGGRAPH_VIZ=save                     # Только для разработки
LANGGRAPH_VIZ_FORMAT=svg
LANGGRAPH_VIZ_PATH=./debug/graph.svg
